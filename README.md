# DataScience_MidCourse_12_21
í†µê³„ ë¶„ì„, ì°¨ì› ì¶•ì†Œ, íšŒê·€ ë¶„ì„, ë¨¸ì‹ ëŸ¬ë‹ ì‹¤ìŠµ í¬í•¨

# ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì¤‘ê¸‰ ê³¼ì • (12_21)

## ğŸ“Œ ê°œìš”
2023ë…„ 12ì›” 21ì— ì´ í”„ë¡œì íŠ¸ëŠ” **ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì¤‘ê¸‰ ê³¼ì •**ì—ì„œ ìˆ˜í–‰í•œ ì‹¤ìŠµ ì½”ë“œì…ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ë°ì´í„° ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì„ ì ìš©í•˜ë©°, ì£¼ìš” ê°œë…ì„ ì‹¤ìŠµì„ í†µí•´ í•™ìŠµí•˜ì˜€ìŠµë‹ˆë‹¤.

## ğŸ› ï¸ ì‚¬ìš©í•œ ê¸°ìˆ 
- **í†µê³„ ë¶„ì„**: ìƒê´€ê´€ê³„ ë¶„ì„, í‰ê·  ë¶„ì„(T-test), ë¶„í¬ ê²€ì •(KS-test)
- **ì°¨ì› ì¶•ì†Œ**: PCA, t-SNE, UMAPì„ ì´ìš©í•œ ë°ì´í„° ì‹œê°í™”
- **íšŒê·€ ë¶„ì„**: ì„ í˜• íšŒê·€ ë° ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¥¼ ì´ìš©í•œ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
- **ë¨¸ì‹ ëŸ¬ë‹**: KNN ë¶„ë¥˜ ëª¨ë¸, K-Means í´ëŸ¬ìŠ¤í„°ë§
- **ë°ì´í„° ì‹œê°í™”**: Matplotlib, Seabornì„ í™œìš©í•œ ë‹¤ì–‘í•œ ë°ì´í„° ì‹œê°í™”

---

## ğŸ”¹ ì£¼ìš” ì‹¤í—˜ ë‚´ìš©

### 1ï¸âƒ£ í†µê³„ ë¶„ì„ (T-test & KS-test)
- íŠ¹ì • ë³€ìˆ˜ ê°„ì˜ í‰ê·  ì°¨ì´ë¥¼ ê²€ì • (p-value í™œìš©)
- KS-testë¥¼ ì´ìš©í•˜ì—¬ ë°ì´í„°ì˜ ë¶„í¬ ë¹„êµ

#### âœ”ï¸ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
```python
from scipy.stats import ttest_ind, ks_2samp

# ë‘ ê·¸ë£¹ ê°„ í‰ê·  ë¹„êµ (T-test)
setosa = subset_df[subset_df['species'] == 'setosa'][feature]
versicolor = subset_df[subset_df['species'] == 'versicolor'][feature]
t_stat, p_val = ttest_ind(setosa, versicolor)
print(f'T-test p-value: {p_val}')

# ë¶„í¬ ë¹„êµ (KS-test)
ks_stat, p_val = ks_2samp(setosa, versicolor)
print(f'KS-test p-value: {p_val}')
```

---

### 2ï¸âƒ£ ì°¨ì› ì¶•ì†Œ ë° ë°ì´í„° ì‹œê°í™”
- PCA, t-SNE, UMAPì„ ì´ìš©í•˜ì—¬ ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì €ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™”

#### âœ”ï¸ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
```python
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from umap import UMAP

# PCA ì‹¤í–‰
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# t-SNE ì‹¤í–‰
tsne = TSNE(n_components=2, random_state=0)
X_tsne = tsne.fit_transform(X)

# UMAP ì‹¤í–‰
umap = UMAP(n_components=2, random_state=0)
X_umap = umap.fit_transform(X)
```

#### ğŸ“Š ì‹œê°í™” ê²°ê³¼
![PCA, t-SNE, UMAP ë¹„êµ](ì´ë¯¸ì§€ê²°ê³¼_1.png)
![MNIST ì°¨ì› ì¶•ì†Œ](ì´ë¯¸ì§€ê²°ê³¼_2.png)

---

### 3ï¸âƒ£ ì„ í˜• íšŒê·€ ë¶„ì„ (ë¶€ë™ì‚° ê°€ê²© ì˜ˆì¸¡ ë“±)
- ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
- ë‹¤ì¤‘ íšŒê·€ ë¶„ì„ì„ í†µí•´ ë³€ìˆ˜ ì¤‘ìš”ë„ í™•ì¸

#### âœ”ï¸ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ëª¨ë¸ ìƒì„± ë° í›ˆë ¨
model = LinearRegression()
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X_test)

# ì„±ëŠ¥ í‰ê°€
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R2 Score: {r2}')
```

#### ğŸ“Š ì‹œê°í™” ê²°ê³¼
![y_test vs. y_pred](ì´ë¯¸ì§€ê²°ê³¼_3.png)

---

### 4ï¸âƒ£ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ ë° í´ëŸ¬ìŠ¤í„°ë§
- KNN ë¶„ë¥˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ë¥˜
- K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ í†µí•´ ë°ì´í„° êµ°ì§‘í™”

#### âœ”ï¸ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ (K-Means)
```python
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X)

# ì‹¤ë£¨ì—£ ì ìˆ˜ ê³„ì‚°
score = silhouette_score(X, labels)
print(f'Silhouette Score: {score}')
```

#### ğŸ“Š ì‹œê°í™” ê²°ê³¼
![K-Means í´ëŸ¬ìŠ¤í„°ë§](ì´ë¯¸ì§€ê²°ê³¼_4.png)

---

## ğŸ“‚ í”„ë¡œì íŠ¸ íŒŒì¼ êµ¬ì„±
- `data_science_mid_12_21.ipynb` : ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì¤‘ê¸‰ ê³¼ì • ì‹¤ìŠµ ì½”ë“œ
- `README.md` : í”„ë¡œì íŠ¸ ê°œìš” ë° ì„¤ëª…
- `ì´ë¯¸ì§€ê²°ê³¼_1.png ~ ì´ë¯¸ì§€ê²°ê³¼_4.png` : ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€

---

## ğŸ”— ê´€ë ¨ ì‚¬í•­
ì´ í”„ë¡œì íŠ¸ëŠ” ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì¤‘ê¸‰ ê³¼ì • ìˆ˜ë£Œ ê³¼ì •ì—ì„œ ì‘ì„±ëœ ì½”ë“œì…ë‹ˆë‹¤.
